{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82e03399-f77b-49cb-b066-0b30984f9c66",
   "metadata": {},
   "source": [
    "# III Neural Network Module\n",
    "Simple LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2837854-3d45-4d03-b661-0a1bb949c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size: int = 1,\n",
    "                 hidden_layer_size: int = 100,\n",
    "                 output_size: int = 1):\n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size)\n",
    "        self.hidden_cell = (torch.zeros(1,1,self.hidden_layer_size),\n",
    "                            torch.zeros(1,1,self.hidden_layer_size))\n",
    "        \n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq: torch.Tensor) -> torch.Tensor:\n",
    "        lstm_out, self.hidden_cell = self.lstm(\n",
    "            input_seq.view(len(input_seq), 1, -1), self.hidden_cell)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0e171e-0b57-4981-bb55-f1dccd09fdb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.linspace(0, 1, 100)\n",
    "seq_length = 10\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0953f132-877b-4423-8d98-de921890b5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLSTM()\n",
    "loss_fun = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):  # number of epochs\n",
    "    for i in range(len(data) - seq_length):\n",
    "        # Prepare data\n",
    "        seq, target = data[i:i+seq_length], data[i+seq_length]\n",
    "        seq = torch.FloatTensor(seq).view(-1, 1, 1)\n",
    "        target = torch.FloatTensor([target])\n",
    "        if epoch == 0 and i == 0:\n",
    "            print(f'{seq=}, {seq.shape=}\\n{target=}, {target.shape=}\\n')\n",
    "\n",
    "        # Reset the gradient and hidden state\n",
    "        optimizer.zero_grad()\n",
    "        model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                             torch.zeros(1, 1, model.hidden_layer_size))\n",
    "\n",
    "        # Forward pass\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        # Compute the loss, perform backward pass, and update weights\n",
    "        loss = loss_fun(y_pred, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss every 10 epochs\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch} Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb3c332-f622-4e14-8b42-9c4fbdfd08e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference\n",
    "with torch.no_grad():\n",
    "    seq = torch.FloatTensor(data[-seq_length:]).view(-1, 1, 1)\n",
    "    model.hidden_cell = (torch.zeros(1, 1, model.hidden_layer_size),\n",
    "                         torch.zeros(1, 1, model.hidden_layer_size))\n",
    "    pred = model(seq)\n",
    "    print(f'Next value prediction for {seq}: {pred.item()}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
